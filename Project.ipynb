{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 4007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current training data size is 581\n",
      "Current validation data size is 581\n",
      "Current test data size is 581\n",
      "... building the model\n",
      "... training\n",
      "('training @ iter = ', 0L)\n"
     ]
    }
   ],
   "source": [
    "from project_test import colorization\n",
    "result = colorization(learning_rate=0.0001, n_epochs=10,\n",
    "                    verbose=True,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will need 0.015625 GBs of free memory\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "T.config.floatX = 'float32'\n",
    "dataPoints = np.random.random((64+64, 256 * 256)).astype(T.config.floatX)\n",
    "#float32 data type requires 4 bytes\n",
    "sizeinGBs = 64 * 256 * 256 * 4 / 1024. / 1024 / 1024 \n",
    "print \"Data will need %2f GBs of free memory\" % sizeinGBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.shape(result[3])\n",
    "print(result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color, io\n",
    "import theano\n",
    "%matplotlib inline\n",
    "\n",
    "data_l = ((result[0][3]).reshape(1,256,256)).transpose(1,2,0)\n",
    "data_ab_y = ((result[1][3]).reshape(2,256,256)).transpose(1,2,0)\n",
    "data_ab_nn = ((result[2][3]).reshape(2,256,256)).transpose(1,2,0)\n",
    "img_construct = np.concatenate((data_l.astype(np.float64),data_ab_nn.astype(np.float64)), axis=2)\n",
    "plt.imshow(color.lab2rgb(img_construct))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data_ab_nn[1,45,1])\n",
    "print(data_ab_y[1,45,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "n_epochs=128\n",
    "verbose=True\n",
    "batch_size=500\n",
    "dir_name='data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = numpy.random.RandomState(23455)\n",
    "    \n",
    "new_path = './data/'\n",
    "if not os.path.isdir(new_path):\n",
    "    download_images(dir_name, 3)\n",
    "    prepare_image_sets(dir_name, batch_size=200)\n",
    "#train_set, valid_set, test_set = \n",
    "train_set = load_data(dir_name,theano_shared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_l_mat, train_set_ab_mat = load_data(dir_name,theano_shared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set_x = shared_dataset(train_set_l_mat)\n",
    "train_set_y = shared_dataset(train_set_ab_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
